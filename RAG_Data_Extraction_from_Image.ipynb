{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "!pip install pytesseract pdf2image pillow\n",
        "\n",
        "# %%\n",
        "!pip install pytesseract pdf2image pillow\n",
        "\n",
        "# %%\n",
        "!apt-get install poppler-utils\n",
        "# Install Tesseract OCR engine\n",
        "!apt-get update\n",
        "!apt-get install tesseract-ocr\n",
        "# Install Marathi language data for Tesseract\n",
        "!apt-get install tesseract-ocr-mar\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-0zAnzonYUX",
        "outputId": "0854b22a-00e1-4fbb-b57f-30eb1823eb81"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytesseract, pdf2image\n",
            "Successfully installed pdf2image-1.17.0 pytesseract-0.3.13\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8 [186 kB]\n",
            "Fetched 186 kB in 0s (439 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,741 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,740 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,630 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,999 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,553 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,979 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,295 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,468 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,245 kB]\n",
            "Fetched 32.0 MB in 4s (9,008 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-mar\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 862 kB of archives.\n",
            "After this operation, 2,133 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-mar all 1:4.00~git30-7274cfa-1.1 [862 kB]\n",
            "Fetched 862 kB in 1s (748 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-mar.\n",
            "(Reading database ... 126141 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-mar_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-mar (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-mar (1:4.00~git30-7274cfa-1.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CMPZyPyGxqt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15445ed7-f1af-4c3c-9fee-54c568499773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text extraction complete!\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "\n",
        "# Path to your PDF\n",
        "pdf_path = \"/content/ArogyaYojanaBookletSample.pdf\"\n",
        "\n",
        "# Convert PDF pages to images\n",
        "# The convert_from_path function now has access to the poppler utilities\n",
        "pages = convert_from_path(pdf_path, dpi=300) # convert pdf into high resolution Images\n",
        "\n",
        "# OCR each image\n",
        "text = \"\"\n",
        "for i, page in enumerate(pages):\n",
        "    # pytesseract will now find the 'mar' language data\n",
        "    text += pytesseract.image_to_string(page, lang='mar')  # 'mar' for Marathi\n",
        "\n",
        "# Save or print text\n",
        "with open(\"output_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text)\n",
        "\n",
        "print(\"Text extraction complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Gemini Model"
      ],
      "metadata": {
        "id": "BK30BfiCqGP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# STEP 1: Configure Gemini API (replace with your actual API key)\n",
        "genai.configure(api_key=\"AIzaSyCT0--b3MsBfcy0s6cfL9OMm7atIBHxbLg\")\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "\n",
        "# STEP 2: Convert PDF to images\n",
        "def pdf_to_images(pdf_path):\n",
        "    images = convert_from_path(pdf_path)\n",
        "    return images\n",
        "\n",
        "# STEP 3: Use Gemini to extract text from each page image\n",
        "def extract_text_from_images(images):\n",
        "    all_text = \"\"\n",
        "    for idx, image in enumerate(images):\n",
        "        print(f\"Processing page {idx + 1}...\")\n",
        "\n",
        "        response = model.generate_content([\n",
        "            \"Please extract and return the Marathi text from this scanned document page.\",\n",
        "            image\n",
        "        ])\n",
        "\n",
        "        page_text = response.text\n",
        "        all_text += f\"\\n--- Page {idx + 1} ---\\n{page_text}\"\n",
        "    return all_text\n",
        "\n",
        "\n",
        "# STEP 4: Run the pipeline\n",
        "pdf_path = \"/content/ArogyaYojanaBookletSample.pdf\"  # Make sure this path is correct\n",
        "images = pdf_to_images(pdf_path)\n",
        "extracted_text = extract_text_from_images(images)\n",
        "\n",
        "# STEP 5: Save result to file\n",
        "with open(\"extracted_marathi_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(extracted_text)\n",
        "\n",
        "print(\"✅ Text extraction complete. Output saved to 'extracted_marathi_text.txt'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "bCPBCl1foBLi",
        "outputId": "6f29a051-f19a-4b9f-d615-49551949725e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing page 1...\n",
            "Processing page 2...\n",
            "Processing page 3...\n",
            "Processing page 4...\n",
            "✅ Text extraction complete. Output saved to 'extracted_marathi_text.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# STEP 1: Configure Gemini API (replace with your actual API key)\n",
        "genai.configure(api_key=\"AIzaSyCT0--b3MsBfcy0s6cfL9OMm7atIBHxbLg\")\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "\n",
        "# STEP 2: Convert PDF to images\n",
        "def pdf_to_images(pdf_path):\n",
        "    images = convert_from_path(pdf_path)\n",
        "    return images\n",
        "\n",
        "# STEP 3: Use Gemini to extract text from each page image\n",
        "def extract_text_from_images(images):\n",
        "    all_text = \"\"\n",
        "    for idx, image in enumerate(images):\n",
        "        print(f\"Processing page {idx + 1}...\")\n",
        "\n",
        "        response = model.generate_content([\n",
        "            \"Please extract and return the English text from this scanned document page.\",\n",
        "            image\n",
        "        ])\n",
        "\n",
        "        page_text = response.text\n",
        "        all_text += f\"\\n--- Page {idx + 1} ---\\n{page_text}\"\n",
        "    return all_text\n",
        "\n",
        "\n",
        "# STEP 4: Run the pipeline\n",
        "pdf_path = \"/content/Document 2.pdf\"  # Make sure this path is correct\n",
        "images = pdf_to_images(pdf_path)\n",
        "extracted_text = extract_text_from_images(images)\n",
        "\n",
        "# STEP 5: Save result to file\n",
        "with open(\"extracted_english_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(extracted_text)\n",
        "\n",
        "print(\"✅ Text extraction complete. Output saved to 'extracted_marathi_text.txt'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "CzIuoL0rqoj9",
        "outputId": "3d1d3690-6e61-4081-90ab-fc439f4121a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing page 1...\n",
            "Processing page 2...\n",
            "Processing page 3...\n",
            "Processing page 4...\n",
            "Processing page 5...\n",
            "Processing page 6...\n",
            "Processing page 7...\n",
            "Processing page 8...\n",
            "Processing page 9...\n",
            "Processing page 10...\n",
            "Processing page 11...\n",
            "Processing page 12...\n",
            "Processing page 13...\n",
            "✅ Text extraction complete. Output saved to 'extracted_marathi_text.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uS6oyc0wxcLq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}